{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torch.utils.data import DataLoader\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from tqdm.notebook import tqdm\n",
    "import albumentations as A\n",
    "\n",
    "# from ipywidgets import IntProgress\n",
    "import multiprocessing\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device\n",
    "import seaborn as sns\n",
    "\n",
    "from torchvision.ops import batched_nms\n",
    "import mmcv\n",
    "\n",
    "from ensemble_boxes import *\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision.ops import box_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img_path, boxes, labels):\n",
    "    \n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image / 255\n",
    "    image = image.astype('float32')\n",
    "    \n",
    "    categories = [\n",
    "        { 'id':0, 'name': 'Aortic enlargement'},\n",
    "        { 'id':1, 'name': 'Atelectasis'},\n",
    "        { 'id':2, 'name': 'Calcification'},\n",
    "        { 'id':3, 'name': 'Cardiomegaly'},\n",
    "        { 'id':4, 'name': 'Consolidation'},\n",
    "        { 'id':5, 'name': 'ILD'},\n",
    "        { 'id':6, 'name': 'Infiltration'},\n",
    "        { 'id':7, 'name': 'Lung Opacity'},\n",
    "        { 'id':8, 'name': 'Nodule/Mass'},\n",
    "        { 'id':9, 'name': 'Other lesion'},\n",
    "        { 'id':10, 'name': 'Pleural effusion'},\n",
    "        { 'id':11, 'name': 'Pleural thickening'},\n",
    "        { 'id':12, 'name': 'Pneumothorax'},\n",
    "        { 'id':13, 'name': 'Pulmonary fibrosis'},\n",
    "        { 'id':14, 'name': 'No finding'},\n",
    "    ] \n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    for box,label in zip(boxes, labels):\n",
    "        cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (225,0,0), 4)\n",
    "        label = categories[label]['name'].upper()\n",
    "#         print(label)\n",
    "        cv2.putText(image, \n",
    "                    label,\n",
    "                    (box[0], box[1]), \n",
    "                    fontFace = cv2.FONT_HERSHEY_COMPLEX, \n",
    "                    fontScale = 1,\n",
    "                    color = (255, 0, 0),\n",
    "                    thickness = 2,\n",
    "                    lineType = cv2.LINE_AA\n",
    "                   )\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('10_fold_dedub_abnormal_org_size.csv')\n",
    "# df = pd.read_csv('train.csv')\n",
    "# abnormal = df[df.class_id != 14].groupby('image_id').agg(lambda x: list(x)).reset_index()\n",
    "\n",
    "# fold_id = 0\n",
    "# train_df = df[df.fold_id != fold_id].groupby('image_id').agg(lambda x: list(x)).reset_index()\n",
    "\n",
    "# fold_id = 1\n",
    "# valid_df = df[df.fold_id == fold_id].groupby('image_id').agg(lambda x: list(x)).reset_index()\n",
    "\n",
    "meta = pd.read_csv('train_meta.csv').set_index('image_id')\n",
    "# fold_id = 1\n",
    "# train_df = df[df.fold_id != fold_id].groupby('image_id').agg(lambda x: list(x)).reset_index()\n",
    "# valid_df = df[df.fold_id == fold_id].groupby('image_id').agg(lambda x: list(x)).reset_index()\n",
    "\n",
    "d = df[(df.class_id == 7) | (df.class_id == 6)].groupby('image_id').agg(lambda x: list(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99968d84ce424587a6f37ce00a3f4790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4394 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def remove_dublicates(df, output_file):\n",
    " \n",
    "    n = len(df)\n",
    "   \n",
    "    df_annotations = []\n",
    "    iou_thr = 0.01\n",
    "  \n",
    "    for idx in tqdm(range(n)):\n",
    "\n",
    "        records = df.loc[idx]\n",
    "        image_id = records['image_id']\n",
    "\n",
    "        width = meta.loc[image_id]['dim1']\n",
    "        height = meta.loc[image_id]['dim0']\n",
    "        \n",
    "        labels = records['class_id']\n",
    "        scores = np.ones(len(labels))\n",
    "        \n",
    "        boxes = records[['x_min','y_min', 'x_max', 'y_max']].to_numpy()\n",
    "        boxes = np.array(boxes.tolist()).T\n",
    "        boxes = boxes.astype(int)\n",
    "        \n",
    "        boxes = boxes.astype(float)\n",
    "        boxes[:, 0] = boxes[:, 0] / width\n",
    "        boxes[:, 2] = boxes[:, 2] / width\n",
    "        boxes[:, 1] = boxes[:, 1] / height\n",
    "        boxes[:, 3] = boxes[:, 3] / height\n",
    "\n",
    "        scores = np.ones(len(labels))\n",
    "\n",
    "#         filtering dublicates from multiple radiologists \n",
    "        boxes, scores, labels = nms([boxes], [scores], [labels], iou_thr=iou_thr)\n",
    "\n",
    "        boxes[:, 0] = boxes[:, 0] * width\n",
    "        boxes[:, 2] = boxes[:, 2] * width\n",
    "        boxes[:, 1] = boxes[:, 1] * height\n",
    "        boxes[:, 3] = boxes[:, 3] * height\n",
    "        \n",
    "        boxes = boxes.astype(int)\n",
    "        \n",
    "        labels = labels.astype(int)\n",
    "        \n",
    "#         img_path = 'train_2x/train/' + image_id + '.jpg'\n",
    "#         print(image_id)\n",
    "#         plot_image(img_path, boxes, labels, scores)\n",
    "\n",
    "        for i in range(len(boxes)):\n",
    "\n",
    "            label = labels[i]\n",
    "\n",
    "            bbox = boxes[i]\n",
    "            area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "                \n",
    "            box_anno = dict(\n",
    "                image_id=image_id,\n",
    "                class_id=label,\n",
    "                x_min=bbox[0],\n",
    "                y_min=bbox[1],\n",
    "                x_max=bbox[2],\n",
    "                y_max=bbox[3],\n",
    "                area=area,\n",
    "                width=width,\n",
    "                height=height)\n",
    "\n",
    "            df_annotations.append(box_anno)\n",
    "            \n",
    "    d = pd.DataFrame(df_annotations)\n",
    "    d.to_csv(output_file, index=False)\n",
    "            \n",
    "\n",
    "remove_dublicates(abnormal, 'abnormal_dedub_org_size.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('10_fold_dedub_abnormal_org_size.csv')\n",
    "\n",
    "fold_id = 0\n",
    "\n",
    "train_df = df[df.fold_id != fold_id].groupby('image_id').agg(lambda x: list(x)).reset_index()\n",
    "valid_df = df[df.fold_id == fold_id].groupby('image_id').agg(lambda x: list(x)).reset_index()\n",
    "# ax = sns.countplot(x=\"class_id\",data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_json(df, output_file):\n",
    "    \n",
    "    categories = [\n",
    "        { 'id':0, 'name': 'Aortic enlargement'},\n",
    "        { 'id':1, 'name': 'Atelectasis'},\n",
    "        { 'id':2, 'name': 'Calcification'},\n",
    "        { 'id':3, 'name': 'Cardiomegaly'},\n",
    "        { 'id':4, 'name': 'Consolidation'},\n",
    "        { 'id':5, 'name': 'ILD'},\n",
    "        { 'id':6, 'name': 'Infiltration'},\n",
    "        { 'id':7, 'name': 'Lung Opacity'},\n",
    "        { 'id':8, 'name': 'Nodule/Mass'},\n",
    "        { 'id':9, 'name': 'Other lesion'},\n",
    "        { 'id':10, 'name': 'Pleural effusion'},\n",
    "        { 'id':11, 'name': 'Pleural thickening'},\n",
    "        { 'id':12, 'name': 'Pneumothorax'},\n",
    "        { 'id':13, 'name': 'Pulmonary fibrosis'},\n",
    "    ] \n",
    "    \n",
    "    n = len(df)\n",
    "\n",
    "    annotations = []\n",
    "    images = []\n",
    "    \n",
    "    obj_count = 0\n",
    "\n",
    "    for idx in tqdm(range(n)):\n",
    "\n",
    "        records = df.loc[idx]\n",
    "        image_id = records['image_id']\n",
    "        \n",
    "        width = meta.loc[image_id]['dim1'] \n",
    "        height = meta.loc[image_id]['dim0']\n",
    "    \n",
    "        images.append(dict(\n",
    "            id=idx,\n",
    "            file_name=image_id + '.jpg',\n",
    "            height=height,\n",
    "            width=width))\n",
    " \n",
    "        boxes = records[['x_min','y_min', 'x_max', 'y_max']].to_numpy()\n",
    "        boxes = np.array(boxes.tolist()).T\n",
    "        boxes = boxes.astype(int)\n",
    "        labels = records['class_id']\n",
    "        \n",
    "#         for i in len(boxes):\n",
    "            \n",
    "#             box_1 = boxes[i]\n",
    "            \n",
    "#             for j in len(boxes):\n",
    "                \n",
    "#                 box_2 = boxes[j]\n",
    "                \n",
    "#                 iou = box_iou(box_1, box_2)\n",
    "\n",
    "#                 if iou > 0.2 and labels[i] == labels[j]:\n",
    "#         scores = np.ones(len(labels))\n",
    "#         img_path = 'vinbigdata/train/' + image_id + '.jpg'\n",
    "#         plot_image(img_path, boxes, labels)        \n",
    "          \n",
    "        for i in range(len(boxes)):\n",
    "\n",
    "            label = labels[i]\n",
    "#             print(categories[label])\n",
    "            bbox = boxes[i]\n",
    "            area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "            \n",
    "#             if bbox[2] - bbox[0] > width * 0.6:\n",
    "#                 continue\n",
    "            \n",
    "            data_anno = dict(\n",
    "                image_id=idx,\n",
    "                id=obj_count,\n",
    "                category_id=label,\n",
    "                bbox=[bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]],\n",
    "                area=area,\n",
    "                iscrowd=0)\n",
    "            \n",
    "            annotations.append(data_anno)\n",
    "            \n",
    "            obj_count += 1\n",
    "    \n",
    "    coco_format_json = dict(\n",
    "        images=images,\n",
    "        annotations=annotations,\n",
    "        categories=categories)\n",
    "    mmcv.dump(coco_format_json, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c09aa736f94a8782d095303bb03c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3959 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_data_json(train_df, 'fold_0_abnormal_train_org_size.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef9052fa8fe43c5b038905a580bdf77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/435 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_data_json(valid_df, 'fold_0_abnormal_valid_org_size.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "function takes exactly 4 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f381b0e5a01a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mplot_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-02173e7269a8>\u001b[0m in \u001b[0;36mplot_image\u001b[0;34m(img_path, boxes, labels, scores)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m225\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#         print(label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: function takes exactly 4 arguments (2 given)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('train_downsampled.csv').groupby('image_id').agg(lambda x: list(x)).reset_index()\n",
    "\n",
    "idx = 100\n",
    "records = df.loc[idx]\n",
    "image_id = records['image_id']\n",
    "\n",
    "img_path = 'train_2x/train/' + image_id + '.jpg'\n",
    "\n",
    "\n",
    "width = meta.loc[image_id]['dim1']\n",
    "height = meta.loc[image_id]['dim0']\n",
    "\n",
    "boxes = records[['x_min','y_min', 'x_max', 'y_max']].to_numpy()\n",
    "boxes = np.array(boxes.tolist()).T\n",
    "labels = records['class_id']\n",
    "scores = np.ones(len(labels))\n",
    "\n",
    "plot_image(img_path, boxes, labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "categories = [\n",
    "    { 'id':0, 'name': 'Aortic enlargement'},\n",
    "    { 'id':1, 'name': 'Atelectasis'},\n",
    "    { 'id':2, 'name': 'Calcification'},\n",
    "    { 'id':3, 'name': 'Cardiomegaly'},\n",
    "    { 'id':4, 'name': 'Consolidation'},\n",
    "    { 'id':5, 'name': 'ILD'},\n",
    "    { 'id':6, 'name': 'Infiltration'},\n",
    "    { 'id':7, 'name': 'Lung Opacity'},\n",
    "    { 'id':8, 'name': 'Nodule/Mass'},\n",
    "    { 'id':9, 'name': 'Other lesion'},\n",
    "    { 'id':10, 'name': 'Pleural effusion'},\n",
    "    { 'id':11, 'name': 'Pleural thickening'},\n",
    "    { 'id':12, 'name': 'Pneumothorax'},\n",
    "    { 'id':13, 'name': 'Pulmonary fibrosis'},\n",
    "] \n",
    "images = []\n",
    "for i in range(len(test_df)):\n",
    "    r = test_df.iloc[i]\n",
    "    image_id = r['image_id']\n",
    "    images.append(dict(\n",
    "        id=i,\n",
    "        file_name=image_id + '.jpg',\n",
    "        height=r['height'],\n",
    "        width=r['width']))\n",
    "coco_format_json = dict(\n",
    "    images=images,\n",
    "    categories=categories)\n",
    "mmcv.dump(coco_format_json, 'test_coco_org.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 700), started 0:00:12 ago. (Use '!kill 700' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-329b952d6f202b3c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-329b952d6f202b3c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir checkpoints_1024_fold_0/tf_logs --port=6008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robert3",
   "language": "python",
   "name": "robert3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
